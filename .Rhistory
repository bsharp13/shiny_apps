output <- paste0(
output,
ifelse(out.unit == 'Miles', ' / mile', ' / km')
)
return(output)
}
base.plot <- function(label) {
ggplot(data = data.frame(x = 1:9, y = 1:9)) +
geom_text(aes(x = 5, y = 5), label = label, size = 10, color = '#337AB7') +
theme_void()
}
#------------------------------------------------------------------------------
# UI
#------------------------------------------------------------------------------
ui <- fluidPage(
br(),
titlePanel('Pace Calculator'),
br(),
sidebarLayout(
sidebarPanel(
fluidRow(
column(
6, radioButtons(
'race_unit',
'Race Unit',
choices = c('Kilometers', 'Miles'),
selected = 'Kilometers',
inline = TRUE
)
),
column(
6, radioButtons(
'pace_unit',
'Pace Unit',
choices = c('Kilometers', 'Miles'),
selected = 'Kilometers',
inline = TRUE
)
)
),
fluidRow(
column(12, numericInput('distance', 'Distance: ', value = 5))
),
fluidRow(
column(4, numericInput('hours', 'Hours: ', value = 0)),
column(4, numericInput('minutes', 'Minutes: ', value = 30)),
column(4, numericInput('seconds', 'Seconds: ', value = 0))
),
fluidRow(
column(
3, p(actionButton(
"calc",
"Compute Pace",
style = "color: #fff; background-color: #337ab7;"
))
)
)
),
mainPanel(
wellPanel(plotOutput('pacePlot', height = '252px'))
)
)
)
#------------------------------------------------------------------------------
# Server
#------------------------------------------------------------------------------
server <- function(input, output) {
output_pace <- eventReactive(input$calc, {
compute.pace(
input$distance,
input$hours,
input$minutes,
input$seconds,
input$race_unit,
input$pace_unit
)
})
output$pacePlot <- renderPlot({
base.plot(output_pace())
})
}
#------------------------------------------------------------------------------
# Run App
#------------------------------------------------------------------------------
shinyApp(ui = ui, server = server)
?rbinom()
y <- rbinom(1000, 1, 0.1)
sum(y)
x1 <- rnorm(1000, 0, 1)
df <- data_frame(y, x)
library(tidyverse)
library(caret)
y <- rbinom(1000, 1, 0.1)
x1 <- rnorm(1000, 0, 1)
df <- data_frame(y, x)
df <- data_frame(y, x1)
for (i in 1:99) {
x <- rnorm(1000, 0, 1)
df <- cbind(df, x)
}
colnames(df) <- c(y, paste0('x', 1:100))
c(y, paste0('x', 1:100))
paste0('x', 1:100)
c(y, paste0('x', 1:100))
colnames(df)[-1] <- paste0('x', 1:100)
set.seed(314)
y <- rbinom(1000, 1, 0.1)
x1 <- rnorm(1000, 0, 1)
df <- data_frame(y, x1)
for (i in 1:99) {
empty <- rbinom(1, 1, 0.05)
if (empty) {
x <- rep(0, 1000)
} else {
x <- rep(1000, 0, 1)
}
df <- cbind(df, x)
}
colnames(df)[-1] <- paste0('x', 1:100)
sums <- colSums(df)
sums
set.seed(314)
y <- rbinom(1000, 1, 0.1)
x1 <- rnorm(1000, 0, 1)
df <- data_frame(y, x1)
for (i in 1:99) {
empty <- rbinom(1, 1, 0.05)
if (empty) {
x <- rep(0, 1000)
} else {
x <- rnorm(1000, 0, 1)
}
df <- cbind(df, x)
}
colnames(df)[-1] <- paste0('x', 1:100)
sums <- colSums(df)
sums
zero_cols <- names(colSums(df)[which(colSums(df) == 0)]
zero_cols <- names(colSums(df)[which(colSums(df) == 0)])
df %>% select(-c(zero_cols))
df %<>% select(-c(zero_cols))
library(magrittr)
df %<>% select(-c(zero_cols))
# Initial Model Selection
#------------------------------------------------------------------------------
nzv <- nearZeroVar(mdrrDescr, saveMetrics= TRUE)
# Initial Model Selection
#------------------------------------------------------------------------------
nzv <- nearZeroVar(df, saveMetrics= TRUE)
View(nzv)
set.seed(314)
y <- rbinom(1000, 1, 0.05)
x1 <- rnorm(1000, 0, 1)
df <- data_frame(y, x1)
for (i in 1:99) {
empty <- rbinom(1, 1, 0.05)
if (empty) {
x <- rep(0, 1000)
} else {
x <- rnorm(1000, 0, 1)
}
df <- cbind(df, x)
}
colnames(df)[-1] <- paste0('x', 1:100)
# Remove Empty Columns
nzv <- nearZeroVar(df, saveMetrics= TRUE)
View(nzv)
# Remove Empty Columns
nzv <- nearZeroVar(df, saveMetrics= TRUE) %>%
filter(nzv)
# Remove Empty Columns
nzv <- nearZeroVar(df, saveMetrics= TRUE) %>%
filter(nzv) %>%
row.names()
# Remove Empty Columns
nzv <- nearZeroVar(df, saveMetrics= TRUE) %>%
filter(nzv) #%>%
View(nzv)
# Remove Empty Columns
nzv <- nearZeroVar(df, saveMetrics= TRUE) #%>%
View(nzv)
# Remove Empty Columns
nzv <- nearZeroVar(df, saveMetrics= TRUE) %>%
rownames_to_column('variable') %>%
filter(nzv) %>%
pull(variable)
# Find Highly Correlated Predictors
df_cor <- cor(df)
# Find Highly Correlated Predictors
mod_x <- df %>% select(-y)
df_cor <- cor(mod_x)
df %<>% select(-c(nzv))
# Find Highly Correlated Predictors
mod_x <- df %>% select(-y)
df_cor <- cor(mod_x)
highly_cor <- findCorrelation(df_cor, cutoff = .80)
df_cor <- cor(mod_x)
highly_cor <- findCorrelation(df_cor, cutoff = .80)
# Filter out linear dependencies
linear_combo <- findLinearCombos(mod_x)
# Filter out linear dependencies
linear_combo <- findLinearCombos(mod_x)$remove
?transparentTheme()
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
# Perform PCA
df %<>% preProcess(method = 'pca')
set.seed(314)
y <- rbinom(1000, 1, 0.05)
x1 <- rnorm(1000, 0, 1)
df <- data_frame(y, x1)
for (i in 1:99) {
empty <- rbinom(1, 1, 0.05)
if (empty) {
x <- rep(0, 1000)
} else {
x <- rnorm(1000, 0, 1)
}
df <- cbind(df, x)
}
colnames(df)[-1] <- paste0('x', 1:100)
# Remove empty columns
nzv <- nearZeroVar(df, saveMetrics= TRUE) %>%
rownames_to_column('variable') %>%
filter(nzv) %>%
pull(variable)
df %<>% select(-c(nzv))
# Find highly correlated predictors
mod_x <- df %>% select(-y)
highly_cor <- findCorrelation(cor(mod_x), cutoff = .80)
mod_x %<>% select(-c(highly_cor))
df %<>% select(-c(highly_cor))
# Filter out linear dependencies
linear_combo <- findLinearCombos(mod_x)$remove
mod_x %<>% select(-c(linear_combo))
df %<>% select(-c(linear_combo))
# Perform PCA
df_pre <- df %>% preProcess(method = 'pca')
# Perform PCA
pca_process <- df %>% preProcess(method = 'pca')
df_clean <- predict(pca_process, df)
View(df_clean)
# Partition data
#------------------------------------------------------------------------------
train_rows <- createDataPartition(df_clean$y, p = 0.6, list = FALSE)
set.seed(314)
y <- rbinom(1000, 1, 0.05)
x1 <- rnorm(1000, 0, 1)
df <- data_frame(y, x1)
for (i in 1:99) {
empty <- rbinom(1, 1, 0.05)
if (empty) {
x <- rep(0, 1000)
} else {
x <- rnorm(1000, 0, 1)
}
df <- cbind(df, x)
}
colnames(df)[-1] <- paste0('x', 1:100)
# Remove empty columns
nzv <- nearZeroVar(df, saveMetrics= TRUE) %>%
rownames_to_column('variable') %>%
filter(nzv) %>%
pull(variable)
df %<>% select(-c(nzv))
# Find highly correlated predictors
mod_x <- df %>% select(-y)
highly_cor <- findCorrelation(cor(mod_x), cutoff = .80)
mod_x %<>% select(-c(highly_cor))
# Filter out linear dependencies
linear_combo <- findLinearCombos(mod_x)$remove
mod_x %<>% select(-c(linear_combo))
# Perform PCA
pca_process <- mod_x %>% preProcess(method = 'pca')
mod_x <- predict(pca_process, mod_x)
mod_y <- df$y
# Partition data
#------------------------------------------------------------------------------
train_rows <- createDataPartition(mod_y, p = 0.6, list = FALSE)
?train()
mod_y <- as.factor(df$y)
# Algorithm Selection
#------------------------------------------------------------------------------
# Define custom train function
my_train <- function(method) {
mod <- train(
x = train_x,
y = train_y,
method = method,
tuneLength = 5,
metric = 'kappa',
trControl = trainControl(verboseIter = TRUE)
)
return(mod)
}
# Logistic Regression (Doesn't use my_train as it requires an extra argument)
mod_lr <- train(
x = train_x,
y = train_y,
method = 'glm',
family = 'binomial',
tuneLength = 5,
metric = 'kappa',
trControl = trainControl(verboseIter = TRUE)
)
train_x <- mod_x[train_rows, ]
test_x <- mod_x[-train_rows, ]
train_y <- mod_y[train_rows]
test_y <- mod_y[-train_rows]
# Algorithm Selection
#------------------------------------------------------------------------------
set.seed(314)
# Define custom train function
my_train <- function(method) {
mod <- train(
x = train_x,
y = train_y,
method = method,
tuneLength = 5,
metric = 'kappa',
trControl = trainControl(verboseIter = TRUE)
)
return(mod)
}
# Logistic Regression (Doesn't use my_train as it requires an extra argument)
mod_lr <- train(
x = train_x,
y = train_y,
method = 'glm',
family = 'binomial',
tuneLength = 5,
metric = 'kappa',
trControl = trainControl(verboseIter = TRUE)
)
warnings()
# Boosted Trees
mod_bt <- my_train('gbm')
# Random Forest
mod_rf <- my_train('ranger')
# Define custom train function
my_train <- function(method) {
mod <- train(
x = train_x,
y = train_y,
method = method,
tuneLength = 5,
metric = 'Kappa',
trControl = trainControl(verboseIter = TRUE)
)
return(mod)
}
prediction <- predict(mod_lr, test_x)
confusionMatrix(test_y, prediction)
true_positive <- sum(prediction == '1' & truth == '1')
truth <- test_y
true_positive <- sum(prediction == '1' & truth == '1')
false_positive <- sum(prediction == '1' & truth == '0')
?precision()
?F_meas()
# Define function to calculate f score
mod_list <- list(mod_lr, mod_bt, mod_rf)
mod_rf$modelType
mod_rf$method
mod_results <- data_frame(
method = lapply(mod_list, function(i) i$method),
f = lapply(mod_list, function(i) {
F_meas(predict(i, test_x), test_y)
})
)
View(mod_results)
mod_bt$times$everything
mod_results <- data_frame(
method = lapply(mod_list, function(i) i$method),
f = lapply(mod_list, function(i) {
F_meas(predict(i, test_x), test_y)
}),
train_time = mod_bt$times$everything$elapsed
)
mod_results <- data_frame(
method = lapply(mod_list, function(i) i$method),
f = lapply(mod_list, function(i) {
F_meas(predict(i, test_x), test_y)
}),
train_time = lapply(mod_list, function(i) i$times$everything$elapsed)
)
mod_lr$times$everything
mod_lr$times$everything['elapsed']
mod_results <- data_frame(
method = lapply(mod_list, function(i) i$method),
f = lapply(mod_list, function(i) {
F_meas(predict(i, test_x), test_y)
}),
train_time = lapply(mod_list, function(i) i$times$everything['system'])
)
View(mod_results)
mod_lr$times$everything['system']
mod_lr$times$everything['user']
mod_lr$times$everything['elapsed']
mod_results <- data_frame(
method = lapply(mod_list, function(i) i$method),
f = lapply(mod_list, function(i) {
F_meas(predict(i, test_x), test_y)
}),
train_time = lapply(mod_list, function(i) i$times$everything['elapsed'])
)
View(mod_results)
mod_results <- data_frame(
method = lapply(mod_list, function(i) i$method),
f = lapply(mod_list, function(i) {
F_meas(predict(i, test_x), test_y)
}),
train_time = lapply(mod_list, function(i) unname(i$times$everything['elapsed']))
)
View(mod_results)
# Plot best models by F score and training time
mod_results %>%
ggplot(aes(x = reorder(method, f), y = f)) +
geom_bar() +
coord_flip()
View(mod_results)
# Plot best models by F score and training time
mod_results %>%
ggplot(aes(x = reorder(method, f + rnorm(1, 0, 0.001)), y = f)) +
geom_bar() +
coord_flip()
reorder(method, f)
View(mod_results)
# Plot best models by F score and training time
mod_results %>%
ggplot(aes(x = method, y = f)) +
geom_bar() +
coord_flip()
# Plot best models by F score and training time
mod_results %>%
ggplot(aes(x = method, y = f)) +
geom_col() +
coord_flip()
lapply(mod_list, function(i) i$method)
as.vector(lapply(mod_list, function(i) i$method))
sapply(mod_list, function(i) i$method)
mod_results <- data_frame(
method = sapply(mod_list, function(i) i$method),
f = sapply(mod_list, function(i) {
F_meas(predict(i, test_x), test_y)
}),
train_time = sapply(mod_list, function(i) {
unname(i$times$everything['elapsed'])
})
)
# Plot best models by F score and training time
mod_results %>%
ggplot(aes(x = method, y = f)) +
geom_col() +
coord_flip()
# Plot best models by F score and training time
mod_results %>%
ggplot(aes(x = reorder(method, f), y = f)) +
geom_col() +
coord_flip()
mod_results %>%
ggplot(aes(x = reorder(method, train_time), y = train_time)) +
geom_col() +
coord_flip()
# Plot best models by F score and training time
mod_results %>%
ggplot(aes(x = reorder(method, f), y = f)) +
geom_col() +
coord_flip() +
labs(x = 'method')
mod_results %>%
ggplot(aes(x = reorder(method, train_time), y = train_time)) +
geom_col() +
coord_flip() +
labs(x = 'method')
mod_results %>%
ggplot(aes(x = reorder(method, train_time), y = train_time)) +
geom_col() +
coord_flip() +
labs(x = 'method', title = 'Train Time by Model')
sort(rep(c('A', 'B', 'C', 'D'), 3))
knitr::opts_chunk$set(echo = TRUE)
df <- data.frame(
treatment = sort(rep(c('A', 'B', 'C', 'D'), 3)),
time_to_relief = c(14, 24, 12, 25, 20, 14, 17, 18, 22, 29, 36, 20)
)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
sort(rep(c('A', 'B', 'C'), 4))
View(df)
df <- data.frame(
treatment = sort(rep(c('A', 'B', 'C'), 4)),
time_to_relief = c(14, 24, 12, 25, 20, 14, 17, 18, 22, 29, 36, 20)
)
View(df)
?kable()
library(shiny)
library(magrittr)
library(tidyverse)
library(lubridate)
runApp('Documents/Misc/Shiny2019/Tracker_2019.R')
runApp('Documents/Misc/Shiny2019/Tracker_2019.R')
library(shiny); runApp('Documents/Git/shiny_apps/ShinyCalendar.R')
library(shiny)
library(magrittr)
library(tidyverse)
library(lubridate)
# Read in data
y2019 <- as.data.frame(read_csv('www/MeData.csv'))
setwd('~/Documents/Git/shiny_apps')
# Read in data
y2019 <- as.data.frame(read_csv('www/MeData.csv'))
View(y2019)
